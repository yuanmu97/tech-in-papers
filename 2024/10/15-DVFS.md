# 15-DVFS
Source: Coordinated Batching and DVFS for DNN Inference on GPU Accelerators

**Why 为什么需要做**

* 模型推理的能耗在许多场景（例如物联网、移动设备）上比较敏感或存在能耗限制

**How 具体要怎么做**

* DVFS: Dynamic Voltage Frequency Scaling，通过动态地根据负载调整处理器（CPU/GPU）的电压和频率的技术，能够降低系统能耗。像包括 intel i7 和高通骁龙在内的很多现代处理器，都实现了 DVFS 功能。
* 那么对于模型推理任务，应用 DVFS 技术的关键在于两点：
  * 负载动态性的源头
    * 如果考虑最简单的情况，数据均匀到达、每个数据处理方式一致，则不存在负载变化，便无从动态调整处理器电压和频率
    * 本工作中是应用了 dynamic batching 带来了负载的动态性（batch size 大，负载大）
    * 其他的一些工作，考虑过结合 early-exit 神经网络（不同的数据可能在不同的位置早退，因而计算负载变化）
    * 以及一些在线模型推理任务也存在天然的负载动态性，例如客服问答服务的负载（深夜负载很低，上下午负载相对较高）

  * 处理器电压/频率与推理效率（延迟、吞吐）的映射
    * 当确定了带来负载动态性的因素，下一步就是要建立我们可以动态调整的参数（处理器电压、频率）与模型推理效率的映射关系
    * 本工作中便是构建了 batch size 与能耗的关系

* 最后的算法设计，则是根据当前负载情况选择最优参数（处理器电压、频率）

**What 做到什么效果**

* 在能耗限制下，相较于只使用 DVFS 或动态 batching，本文的方法实现了 11.2x 和 2.2x 的吞吐

**Comments**

* 今天审稿第一次看到 DVFS 这个技术，然后找到了这篇已发表的文章。简单学习了，但是对于如何用代码实现对处理器电压和频率的控制还没有概念，之后会继续多了解。
