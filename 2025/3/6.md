# Web Agent

今早看了 Manus 的 agent 演示 demo 感觉很惊艳，其中最好奇的一点是：agent 直接能在 web 上进行 UI 交互。这个在我对 agent 调用 APIs 的能力认识之外，所以做了一些学习。



我主要比较关注 web agent 以什么信息作为输入，利用 grok 的 deepsearch 功能帮我做了如下总结：

### 关键要点
- 研究表明，基于LLM的网页代理主要分为两类：以网页HTML为输入和以网页视觉信息为输入。
- 以HTML为输入的代理通过解析HTML代码理解网页结构，适合处理静态内容。
- 以视觉信息为输入的代理使用多模态模型处理网页截图，适合处理动态或复杂布局。
- 证据倾向于认为视觉输入代理在处理实时交互时更有效，但HTML输入代理在精确信息提取方面更可靠。

> [!Tip]
>
> 由于网页存在一些动态内容，直觉来看最终应该还是会发展到基于视觉输入的 agent，也更接近于人类

### 概述
基于大型语言模型（LLM）的网页代理是一种能够自动与网页交互、执行任务的AI程序。根据输入类型，它们可以分为两类：以网页HTML为输入和以网页视觉信息为输入。每类都有其独特的应用场景和优势。

#### 以HTML为输入的代理
这些代理直接处理网页的HTML代码，解析其结构和内容。它们通常使用LLM来提取相关信息，执行如表单填写或数据抓取等任务。这种方法适合处理静态网页，精度高，但可能难以应对动态或JavaScript生成的复杂内容。

#### 以视觉信息为输入的代理
这些代理使用网页的视觉表示，如截图，通过多模态模型（结合图像和文本处理能力）理解页面布局和内容。它们适合处理动态内容和复杂布局，但视觉数据的解释可能存在误差，尤其是在相似元素或低质量图像的情况下。

### 意外细节
一个有趣的发现是，视觉输入代理在处理实时交互（如用户界面自动化）时表现更佳，而HTML输入代理在需要精确信息提取（如网页抓取）时更可靠。这种差异源于它们的输入处理方式，视觉代理更接近人类感知，而HTML代理更依赖结构化数据。

---

### 详细调研报告

#### 引言
基于LLM的网页代理是AI领域的一个重要发展方向，旨在自动化网页交互任务。根据输入类型，它们可以分为以网页HTML为输入和以网页视觉信息为输入两类。本报告将详细探讨这两类工作的研究现状、关键项目和论文，以及它们的优势与挑战。

#### 以网页HTML为输入的代理
这些代理通过解析网页的HTML代码来理解其结构和内容。HTML是一种标记语言，定义了网页的元素和布局，适合静态内容的处理。以下是相关研究和项目的概述：

- **WebAgent**:
  - 描述：WebAgent是一个现实世界的网页代理，使用HTML-T5模型总结HTML文档，并结合Flan-U-PaLM进行生成 python 程序进行操作。它能够处理长达7K到14K标记的真实网站HTML，预处理时移除无关标签（如\<script\>、\<meta\>），保留必要属性（如id、type、value）。
  - 以 html 为输入；模型包括一个 finetuned HTML-T5 和一个 Flan-U-PaLM；action 是 open-ended 的，因为是生成 python 程序进行操作。
  - 性能：相比基线，成功率提升超过50%，在房地产网站上达到65%成功率（87.6%得分），社交媒体网站70%（85.8%得分），地图网站80%（93.8%得分）。
  - 参考：["A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"](https://arXiv.org/abs/2307.12856)
  
- **AgentOccam**:
  - 描述：AgentOccam是一个简单但强大的LLM-based网页代理基线，处理包括HTML在内的网页观察。它通过精简动作空间和优化观察内容，显著提升任务成功率。
  - 性能：在WebArena基准测试中，超越先前最佳方法9.8个百分点（+29.4%）。
  - 参考：["AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents"](https://arXiv.org/abs/2410.13825)

- **WebArena**:
  - 描述：WebArena是一个用于构建自主代理的现实网页环境，涉及HTML处理，支持从简单表单填写到多网站任务的复杂场景。
  - 资源：网站[webarena.dev](https://webarena.dev/)，GitHub[github.com/web-arena-x/webarena](https://github.com/web-arena-x/webarena)

- **LangChain**:
  - 描述：LangChain是一个基于语言模型的应用程序和代理开发框架，可用于构建处理HTML的网页代理。
  - 资源：网站[langchain.com](https://www.langchain.com/)

- **AutoGen**:
  - 描述：AutoGen是一个构建LLM-based代理的框架，支持与网页的交互，可能涉及HTML处理。
  - 资源：网站[autogen.org](https://www.autogen.org/)

**优势与挑战**：
- 优势：HTML输入代理能够精确解析网页结构，适合静态内容和需要高精度信息提取的任务。
- 挑战：可能难以处理动态内容或JavaScript生成的复杂布局，尤其是在HTML文档过长时（平均7K到14K标记）。

#### 以网页视觉信息为输入的代理
这些代理使用网页的视觉表示，如截图，通过多模态模型处理图像和文本，理解页面布局和内容。它们适合动态内容和复杂布局的场景。以下是相关研究和项目的概述：

- **VisualWebArena**:
  - 描述：VisualWebArena是一个评估多模态代理在现实视觉网页任务上的基准测试，所有挑战都以视觉为锚，25.2%的任务需要理解交错图像。
  - 性能：视觉语言模型（VLM）最高成功率16.4%，人类表现为88.7%。一个新VLM代理方法受Set-of-Marks提示策略启发，改善了在图形复杂网页上的表现。
  - 资源：论文["VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks"](https://arXiv.org/abs/2401.13649)，GitHub[github.com/web-arena-x/visualwebarena](https://github.com/web-arena-x/visualwebarena)

- **VLM-based Agents**:
  - 描述：使用视觉语言模型（如GPT-4V）的代理，处理网页截图，结合文本指令执行任务。
  - 示例：可能包括集成VLM的网页导航项目。
  - 我自己找到一个 seeact https://arxiv.org/pdf/2401.01614
  
- **Multimodal LLMs**:
  - 描述：如GPT-4V、Gemini等模型，能够处理图像和文本输入，用于视觉信息处理。
  - 资源：网站[openai.com/products/gpt-4-vision](https://openai.com/products/gpt-4-vision)，[gemini.google](https://gemini.google/)

- **视觉网页代理研究**:
  - 描述：专注于使用视觉输入导航网页的研究，如"Building Visual Agents that can Navigate the Web Autonomously"。
  - 参考：["Building Visual Agents that can Navigate the Web Autonomously"](https://medium.com/towards-data-science/building-visual-agents-that-can-navigate-the-web-autonomously-1184efbfe895)

**优势与挑战**：
- 优势：视觉输入代理能够处理任何类型的网页，包括动态内容和复杂布局，接近人类感知。
- 挑战：视觉数据的解释可能存在误差，尤其是在相似元素或低质量图像的情况下，当前VLM成功率仅16.4%，远低于人类88.7%。

#### 比较与讨论
HTML输入代理在精确信息提取方面更可靠，适合静态网页和结构化任务。视觉输入代理在处理实时交互和动态内容时更有效，但受限于视觉解释的准确性。两者可能结合使用，例如HTML提供精确数据，视觉提供上下文理解。

#### 性能对比表
以下是两类代理在关键基准测试中的性能对比：

| 基准测试/模型         | HTML输入代理成功率 | 视觉输入代理成功率 | 人类表现 |
| --------------------- | ------------------ | ------------------ | -------- |
| WebArena (HTML)       | 65%-80%            | -                  | -        |
| VisualWebArena (视觉) | -                  | 16.4%              | 88.7%    |

#### 结论
研究表明，基于LLM的网页代理在HTML和视觉输入方面各有优势。HTML输入代理适合静态内容，视觉输入代理适合动态交互。未来可能结合两者，提升整体性能。

#### 关键引用
- ["A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"](https://arXiv.org/abs/2307.12856)
- ["AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents"](https://arXiv.org/abs/2410.13825)
- ["VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks"](https://arXiv.org/abs/2401.13649)
- ["Building Visual Agents that can Navigate the Web Autonomously"](https://medium.com/towards-data-science/building-visual-agents-that-can-navigate-the-web-autonomously-1184efbfe895)
- [WebArena: A Realistic Web Environment for Building Autonomous Agents](https://webarena.dev/)
- [VisualWebArena is a benchmark for multimodal agents](https://github.com/web-arena-x/visualwebarena)
- [Code repo for WebArena: A Realistic Web Environment for Building Autonomous Agents](https://github.com/web-arena-x/webarena)
- [LangChain: a framework for developing applications and agents powered by language models](https://www.langchain.com/)
- [AutoGen: a framework for building LLM-based agents](https://www.autogen.org/)
- [OpenAI: products including GPT-4 Vision](https://openai.com/products/gpt-4-vision)
- [Google Gemini: multimodal AI model](https://gemini.google/)

---

除了 grok 调研到的工作之外，我还看到了一些：

* WebWalker: Benchmarking LLMs in Web Traversal 主要关注的问题是 web 理解可能涉及多层的交互（很多网页信息在 sub-pages 里），进而提出了一个新的任务称为 web traversal，即给定一个网页，系统地遍历这个网页及其子网页以充分获取信息。
  * 以 html 文本为输入；模型包括一个 explorer agent（基于ReAct） 和一个 critic agent（用于维护记忆和生成相应）；action 只有 click





我又让 grok 根据三个角度（输入、模型、action）做了总结：

以下是现有网页代理工作的总结，基于输入数据（HTML文本或网页视觉画面）、使用的模型和支持的动作：

#### HTML输入代理
- **WebAgent**：输入HTML文本，使用HTML-T5和Flan-U-PaLM模型，支持点击、输入和导航等标准网页动作。
- **AgentOccam**：输入HTML文本，使用GPT-4-turbo模型，支持标准网页动作。
- **AgentLLM**：输入HTML文本，使用WizardLM模型，支持标准网页动作。
- **WebGPT**：输入HTML文本，使用微调的GPT-3模型，主要支持网页浏览以回答问题。

#### 视觉输入代理
- **VisualWebArena代理**：输入网页截图，使用如GPT-4V和Gemini的多模态模型，支持标准网页动作。
- **WebVoyager（多模态）**：输入视觉画面，使用大型多模态模型（可能为GPT-4V），支持标准网页动作。
- **GPT-4V作为网页代理**：输入视觉画面，使用GPT-4V模型，支持标准网页动作。

研究表明，HTML输入代理更适合静态内容和精确信息提取，而视觉输入代理在处理动态交互时表现更好。意外的是，视觉代理的成功率（如VisualWebArena中仅16.4%）远低于人类（88.7%），显示当前技术仍有局限。

---

### 详细调研报告

基于大型语言模型（LLM）的网页代理是一种能够自动与网页交互、执行任务的AI程序。根据输入类型，它们可以分为两类：以网页HTML为输入和以网页视觉信息为输入。每类都有其独特的应用场景和优势。本报告将详细探讨这两类工作的研究现状、关键项目和论文，以及它们的优势与挑战。

#### HTML输入代理
这些代理通过解析网页的HTML代码来理解其结构和内容，适合处理静态网页。以下是相关研究和项目的概述：

- **WebAgent**：
  - **输入数据**：HTML文本，经过清理移除无关标签（如`<script>`、`<meta>`），保留必要属性（如`id`、`type`、`value`），结合自然语言指令。
  - **使用的LLM型号**：HTML-T5用于规划和总结，Flan-U-PaLM用于生成代码。
  - **支持的动作**：标准网页动作，如点击元素、输入文本、导航页面，通常通过生成Python程序（如使用Selenium）与浏览器交互。
  - **性能**：在房地产网站成功率65%，社交媒体70%，地图网站80%（[WebAgent Paper](https://arXiv.org/abs/2307.12856)）。
  - **资源**：论文[WebAgent: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis](https://arXiv.org/abs/2307.12856)。

- **AgentOccam**：
  - **输入数据**：HTML文本，优化观察内容。
  - **使用的LLM型号**：GPT-4-turbo。
  - **支持的动作**：标准网页动作，通过精简动作空间提升性能。
  - **性能**：在WebArena基准测试中，成功率提升29.4%，超越先前最佳方法9.8个百分点（[AgentOccam Paper](https://arXiv.org/abs/2410.13825)）。
  - **资源**：论文[AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents](https://arXiv.org/abs/2410.13825)。

- **AgentLLM**：
  - **输入数据**：HTML文本，作为浏览器原生自主代理的证明概念。
  - **使用的LLM型号**：WizardLM，基于开源LLM。
  - **支持的动作**：标准网页动作，处理复杂目标导向任务。
  - **资源**：GitHub[AgentLLM: Autonomous AI Agents based on browser-native LLMs](https://github.com/idosal/AgentLLM)。

- **WebGPT**：
  - **输入数据**：HTML文本，使用文本浏览环境。
  - **使用的LLM型号**：微调的GPT-3。
  - **支持的动作**：网页浏览以回答问题，包括提交搜索查询、跟随链接和滚动页面。
  - **性能**：在Reddit问题上，答案被人类评委偏好69%（[WebGPT Paper](https://arXiv.org/abs/2112.09332)）。
  - **资源**：论文[WebGPT: Browser-assisted question-answering with human feedback](https://arXiv.org/abs/2112.09332)。

**优势与挑战**：
- 优势：HTML输入代理能够精确解析网页结构，适合静态内容和需要高精度信息提取的任务。
- 挑战：可能难以处理动态内容或JavaScript生成的复杂布局，尤其是在HTML文档过长时（平均7K到14K标记）。

#### 视觉输入代理
这些代理使用网页的视觉表示，如截图，通过多模态模型处理，适合动态内容和复杂布局。以下是相关研究和项目的概述：

- **VisualWebArena代理**：
  - **输入数据**：视觉画面（网页截图），25.2%的任务需要理解交错的图像-文本输入。
  - **使用的VLM型号**：多模态模型如GPT-4V、Gemini-Pro、IDEFICS-80B-Instruct等。
  - **支持的动作**：标准网页动作，如点击、输入、导航，但决策基于视觉输入。
  - **性能**：最高VLM成功率16.4%，人类表现88.7%，涉及910个任务（[VisualWebArena Paper](https://arXiv.org/abs/2401.13649)）。
  - **资源**：论文[VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://arXiv.org/abs/2401.13649)，GitHub[VisualWebArena benchmark](https://github.com/web-arena-x/visualwebarena)。

- **WebVoyager（多模态）**：
  - **输入数据**：视觉画面，使用大型多模态模型。
  - **使用的VLM型号**：大型多模态模型（可能为GPT-4V）。
  - **支持的动作**：标准网页动作，完成实时网站任务。
  - **性能**：任务成功率55.7%，超越GPT-4（所有工具）和文本-only设置（[WebVoyager Paper](https://huggingface.co/papers/2401.13919)）。
  - **资源**：论文[WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://huggingface.co/papers/2401.13919)。

- **GPT-4V作为网页代理**：
  - **输入数据**：视觉画面，处理实时网站截图。
  - **使用的VLM型号**：GPT-4V。
  - **支持的动作**：标准网页动作，通过SEEACT框架集成视觉理解和行动。
  - **性能**：在实时网站上完成51.1%任务（[GPT-4V Paper](https://arXiv.org/abs/2401.01614)）。
  - **资源**：论文[GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://arXiv.org/abs/2401.01614)。
  - > [!TIP]
    >
    > 这里的 grounded 指的是人工根据 GPT-4V 输出的文本进行网页操作，实验表明效果很好。但是如何从文本信息自动化到网页操作，还是一个技术挑战，文章提出了一种新的结合文本和视觉信息的 grounding 方法。

**优势与挑战**：

- 优势：视觉输入代理能够处理任何类型的网页，包括动态内容和复杂布局，接近人类感知。
- 挑战：视觉数据的解释可能存在误差，尤其是在相似元素或低质量图像的情况下，当前VLM成功率仅16.4%，远低于人类88.7%。

#### 比较与讨论
HTML输入代理在精确信息提取方面更可靠，适合静态网页和结构化任务。视觉输入代理在处理实时交互和动态内容时更有效，但受限于视觉解释的准确性。两者可能结合使用，例如HTML提供精确数据，视觉提供上下文理解。

#### 性能对比表
以下是两类代理在关键基准测试中的性能对比：

| 基准测试/模型         | HTML输入代理成功率 | 视觉输入代理成功率 | 人类表现 |
| --------------------- | ------------------ | ------------------ | -------- |
| WebArena (HTML)       | 65%-80%            | -                  | -        |
| VisualWebArena (视觉) | -                  | 16.4%              | 88.7%    |

#### 结论
研究表明，基于LLM的网页代理在HTML和视觉输入方面各有优势。HTML输入代理适合静态内容，视觉输入代理适合动态交互。未来可能结合两者，提升整体性能。

---

### 关键引用
- [WebAgent: A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis](https://arXiv.org/abs/2307.12856)
- [AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents](https://arXiv.org/abs/2410.13825)
- [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://arXiv.org/abs/2401.13649)
- [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://huggingface.co/papers/2401.13919)
- [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://arXiv.org/abs/2401.01614)
- [WebGPT: Browser-assisted question-answering with human feedback](https://arXiv.org/abs/2112.09332)
- [AgentLLM: Autonomous AI Agents based on browser-native LLMs](https://github.com/idosal/AgentLLM)
- [VisualWebArena benchmark](https://github.com/web-arena-x/visualwebarena)
